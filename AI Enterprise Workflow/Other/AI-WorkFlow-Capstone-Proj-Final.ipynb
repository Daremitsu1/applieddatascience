{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI WorkFlow Capstone Proj (final part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i). The following python codes concisely show laoding about 21 json formatted files into a dataframe, and to print out the top 10 countries (order by Revenue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii). Please review the 12 questions of AI-Workflow beblow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "collection of functions for the final case study solution\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [\"darkorange\",\"royalblue\",\"slategrey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\".\",\"cs-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [os.path.join(data_dir,f) for f in os.listdir(data_dir) if re.search(\"\\.json\",f)]\n",
    "correct_columns = ['country', 'customer_id', 'day', 'invoice', 'month',\n",
    "                       'price', 'stream_id', 'times_viewed', 'year']\n",
    "\n",
    "    ## read data into a temp structure\n",
    "all_months = {}\n",
    "for file_name in file_list:\n",
    "    df = pd.read_json(file_name)\n",
    "    all_months[os.path.split(file_name)[-1]] = df\n",
    "\n",
    "    ## ensure the data are formatted with correct columns\n",
    "for f,df in all_months.items():\n",
    "    cols = set(df.columns.tolist())\n",
    "    if 'StreamID' in cols:\n",
    "        df.rename(columns={'StreamID':'stream_id'},inplace=True)\n",
    "    if 'TimesViewed' in cols:\n",
    "        df.rename(columns={'TimesViewed':'times_viewed'},inplace=True)\n",
    "    if 'total_price' in cols:\n",
    "        df.rename(columns={'total_price':'price'},inplace=True)\n",
    "\n",
    "    cols = df.columns.tolist()\n",
    "    if sorted(cols) != correct_columns:\n",
    "        raise Exception(\"columns name could not be matched to correct cols\")\n",
    "\n",
    "    ## concat all of the data\n",
    "df = pd.concat(list(all_months.values()),sort=True)\n",
    "years,months,days = df['year'].values,df['month'].values,df['day'].values \n",
    "dates = [\"{}-{}-{}\".format(years[i],str(months[i]).zfill(2),str(days[i]).zfill(2)) for i in range(df.shape[0])]\n",
    "df['invoice_date'] = np.array(dates,dtype='datetime64[D]')\n",
    "df['invoice'] = [re.sub(\"\\D+\",\"\",i) for i in df['invoice'].values]\n",
    "    \n",
    "    ## sort by date and reset the index\n",
    "df.sort_values(by='invoice_date',inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>day</th>\n",
       "      <th>invoice</th>\n",
       "      <th>month</th>\n",
       "      <th>price</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>times_viewed</th>\n",
       "      <th>year</th>\n",
       "      <th>invoice_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>6.95</td>\n",
       "      <td>85048</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>6.75</td>\n",
       "      <td>79323W</td>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>2.10</td>\n",
       "      <td>22041</td>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>1.25</td>\n",
       "      <td>21232</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>13085.0</td>\n",
       "      <td>28</td>\n",
       "      <td>489434</td>\n",
       "      <td>11</td>\n",
       "      <td>1.65</td>\n",
       "      <td>22064</td>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017-11-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  customer_id  day invoice  month  price stream_id  \\\n",
       "0  United Kingdom      13085.0   28  489434     11   6.95     85048   \n",
       "1  United Kingdom      13085.0   28  489434     11   6.75    79323W   \n",
       "2  United Kingdom      13085.0   28  489434     11   2.10     22041   \n",
       "3  United Kingdom      13085.0   28  489434     11   1.25     21232   \n",
       "4  United Kingdom      13085.0   28  489434     11   1.65     22064   \n",
       "\n",
       "   times_viewed  year invoice_date  \n",
       "0            12  2017   2017-11-28  \n",
       "1            12  2017   2017-11-28  \n",
       "2            21  2017   2017-11-28  \n",
       "3             5  2017   2017-11-28  \n",
       "4            17  2017   2017-11-28  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing ...and obtaining the original dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "country = None\n",
    "df_orig = df\n",
    "\n",
    "if country:\n",
    "    if country not in np.unique(df_orig['country'].values):\n",
    "        raise Excpetion(\"country not found\")\n",
    "    \n",
    "    mask = df_orig['country'] == country\n",
    "    df = df_orig[mask]\n",
    "else:\n",
    "    df = df_orig\n",
    "\"\"\"\n",
    " \n",
    "    ## use a date range to ensure all days are accounted for in the data\n",
    "invoice_dates = df['invoice_date'].values\n",
    "start_month = '{}-{}'.format(df['year'].values[0],str(df['month'].values[0]).zfill(2))\n",
    "stop_month = '{}-{}'.format(df['year'].values[-1],str(df['month'].values[-1]).zfill(2))\n",
    "df_dates = df['invoice_date'].values.astype('datetime64[D]')\n",
    "days = np.arange(start_month,stop_month,dtype='datetime64[D]')\n",
    "    \n",
    "purchases = np.array([np.where(df_dates==day)[0].size for day in days])\n",
    "invoices = [np.unique(df[df_dates==day]['invoice'].values).size for day in days]\n",
    "streams = [np.unique(df[df_dates==day]['stream_id'].values).size for day in days]\n",
    "views =  [df[df_dates==day]['times_viewed'].values.sum() for day in days]\n",
    "revenue = [df[df_dates==day]['price'].values.sum() for day in days]\n",
    "year_month = [\"-\".join(re.split(\"-\",str(day))[:2]) for day in days]\n",
    "\n",
    "df_time = pd.DataFrame({'date':days,\n",
    "                        'purchases':purchases,\n",
    "                        'unique_invoices':invoices,\n",
    "                        'unique_streams':streams,\n",
    "                        'total_views':views,\n",
    "                        'start_month':start_month,\n",
    "                        'stop_month':stop_month,\n",
    "                        'year_month':year_month,\n",
    "                        'revenue':revenue})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>purchases</th>\n",
       "      <th>unique_invoices</th>\n",
       "      <th>unique_streams</th>\n",
       "      <th>total_views</th>\n",
       "      <th>start_month</th>\n",
       "      <th>stop_month</th>\n",
       "      <th>year_month</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-11-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  purchases  unique_invoices  unique_streams  total_views  \\\n",
       "0 2017-11-01          0                0               0            0   \n",
       "1 2017-11-02          0                0               0            0   \n",
       "2 2017-11-03          0                0               0            0   \n",
       "3 2017-11-04          0                0               0            0   \n",
       "4 2017-11-05          0                0               0            0   \n",
       "\n",
       "  start_month stop_month year_month  revenue  \n",
       "0     2017-11    2019-07    2017-11      0.0  \n",
       "1     2017-11    2019-07    2017-11      0.0  \n",
       "2     2017-11    2019-07    2017-11      0.0  \n",
       "3     2017-11    2019-07    2017-11      0.0  \n",
       "4     2017-11    2019-07    2017-11      0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the total days within the date span\n",
    "len(df_time.date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>3.521514e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EIRE</th>\n",
       "      <td>1.070692e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>4.927182e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>4.056514e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>3.849475e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>1.604099e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hong Kong</th>\n",
       "      <td>1.445257e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portugal</th>\n",
       "      <td>1.352867e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Singapore</th>\n",
       "      <td>1.317592e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>1.232280e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     revenue\n",
       "country                     \n",
       "United Kingdom  3.521514e+06\n",
       "EIRE            1.070692e+05\n",
       "Germany         4.927182e+04\n",
       "France          4.056514e+04\n",
       "Norway          3.849475e+04\n",
       "Spain           1.604099e+04\n",
       "Hong Kong       1.445257e+04\n",
       "Portugal        1.352867e+04\n",
       "Singapore       1.317592e+04\n",
       "Netherlands     1.232280e+04"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dat = sum data\n",
    "\n",
    "# df.groupby('a')['b'].sum()[1]\n",
    "# purchases = np.array([np.where(df_dates==day)[0].size for day in days])\n",
    "# country = [np.unique(df[df_dates==day]['country'].values) for day in days]\n",
    "\n",
    "revenue = df.groupby('country')['price'].sum()\n",
    "country = df.country.unique()\n",
    "\n",
    "dat = pd.DataFrame({#'country':country,\n",
    "                    'revenue':revenue})\n",
    "\n",
    "\n",
    "\n",
    "    # the top 10 countries (order by Revenue)\n",
    "_top_10 = dat.sort_values('revenue',ascending=False)\n",
    "\n",
    "    # print out\n",
    "_top_10[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df,training=True):\n",
    "    \"\"\"\n",
    "    for any given day the target becomes the sum of the next days revenue\n",
    "    for that day we engineer several features that help predict the summed revenue\n",
    "    \n",
    "    the 'training' flag will trim data that should not be used for training\n",
    "    when set to false all data will be returned\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    ## extract dates\n",
    "    dates = df['date'].values.copy()\n",
    "    dates = dates.astype('datetime64[D]')\n",
    "\n",
    "    ## engineer some features\n",
    "    eng_features = defaultdict(list)\n",
    "    previous =[7, 14, 28, 70]  #[7, 14, 21, 28, 35, 42, 49, 56, 63, 70]\n",
    "    y = np.zeros(dates.size)\n",
    "    for d,day in enumerate(dates):\n",
    "\n",
    "        ## use windows in time back from a specific date\n",
    "        for num in previous:\n",
    "            current = np.datetime64(day, 'D') \n",
    "            prev = current - np.timedelta64(num, 'D')\n",
    "            mask = np.in1d(dates, np.arange(prev,current,dtype='datetime64[D]'))\n",
    "            eng_features[\"previous_{}\".format(num)].append(df[mask]['revenue'].sum())\n",
    "\n",
    "        ## get get the target revenue    \n",
    "        plus_30 = current + np.timedelta64(30,'D')\n",
    "        mask = np.in1d(dates, np.arange(current,plus_30,dtype='datetime64[D]'))\n",
    "        y[d] = df[mask]['revenue'].sum()\n",
    "\n",
    "        ## attempt to capture monthly trend with previous years data (if present)\n",
    "        start_date = current - np.timedelta64(365,'D')\n",
    "        stop_date = plus_30 - np.timedelta64(365,'D')\n",
    "        mask = np.in1d(dates, np.arange(start_date,stop_date,dtype='datetime64[D]'))\n",
    "        eng_features['previous_year'].append(df[mask]['revenue'].sum())\n",
    "\n",
    "        ## add some non-revenue features\n",
    "        minus_30 = current - np.timedelta64(30,'D')\n",
    "        mask = np.in1d(dates, np.arange(minus_30,current,dtype='datetime64[D]'))\n",
    "        eng_features['recent_invoices'].append(df[mask]['unique_invoices'].mean())\n",
    "        eng_features['recent_views'].append(df[mask]['total_views'].mean())\n",
    "\n",
    "    X = pd.DataFrame(eng_features)\n",
    "    ## combine features in to df and remove rows with all zeros\n",
    "    X.fillna(0,inplace=True)\n",
    "    mask = X.sum(axis=1)>0\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    dates = dates[mask]\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if training == True:\n",
    "        ## remove the last 30 days (because the target is not reliable)\n",
    "        mask = np.arange(X.shape[0]) < np.arange(X.shape[0])[-30]\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        dates = dates[mask]\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return(X,y,dates)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    run_start = time.time() \n",
    "    data_dir = os.path.join(\"..\",\"data\",\"cs-train\")\n",
    "    print(\"...fetching data\")\n",
    "\n",
    "    ts_all = fetch_ts(data_dir,clean=False)\n",
    "\n",
    "    m, s = divmod(time.time()-run_start,60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print(\"load time:\", \"%d:%02d:%02d\"%(h, m, s))\n",
    "\n",
    "    for key,item in ts_all.items():\n",
    "        print(key,item.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Answers of the 12-Question of AI Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Are there unit tests for the API?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Yes. Unit testing is the process of testing small portions of the software, also known as units. This is done one test at a time, to verify that an expected result is returned under controlled conditions. Importantly, the unit tests are usually organized as a suite and return objective evidence, in the form of a boolean value, which is a key element that enables workflow automation.\n",
    "   One of the reasons to create unit tests is to ensure that iterative improvements to code do not break the functionality of the API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Are there unit tests for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Yes. Unit testing is the process of testing small portions of the software, also known as units. This is done one test at a time, to verify that an expected result is returned under controlled conditions. Importantly, the unit tests are usually organized as a suite and return objective evidence, in the form of a boolean value, which is a key element that enables workflow automation.\n",
    "   One of the reasons to create unit tests is to ensure that iterative improvements to code do not break the functionality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Are there unit tests for the logging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. Like all problems in data science, performance monitoring starts with collecting the right data in the right format. Data for performance monitoring is generally collected using log files. Basically, there are key requirements for performance monitoring for most model deployment projects (logging): runtime, timestamp, prediction, input_data_summary & model_version_number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Can all of the unit tests be run with a single script and do all of the unit tests pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. But If one of the tests were more comprehensive, for example an API test that tested multiple functions, it would likely fall under the umbrella of integration testing. Both unit tests and integration tests are part of the CI/CD pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Is there a mechanism to monitor performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Because performance monitoring is a concern in nearly all customer-facing computer systems, there is a well-established set of tools and techniques for collecting this data. Data for performance monitoring is generally collected using log files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Was there an attempt to isolate the read/write unit tests from production models and logs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes - but in this situation we should assume that the data science team has decided to keep containers as isolated as possible. One reason for this approach would be that the company uses a hybrid cloud or multicloud architecture of storage and services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Does the API work as expected? For example, can you get predictions for a specific country as well as for all countries combined?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. The API works well as we can get predicitons for a specific country as well as for all countries combined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Does the data ingestion exists as a function or script to facilitate automation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Any form of data movement from source to target can be considered as data ingestion. In reality,  A common database as a target is next to impossible due to logistical and privacy concerns,but API keys could be a viable solution towards automation. Another comprehensive solutions automation can be achieved with scripting. And cron jobs are an incredibly powerful way to automate the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Were multiple models compared?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes - they were compared. How well a model performs can be decomposed as bias, variance and noise. The bias of a model is its average error when a model is subjected to different training sets and it comes from the underlying model assumptions. The variance of a model is reflective of how sensitive it is to variations in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Did the EDA investigation use visualizations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. The first task in data science is always data visualization. The data visualization deliverables have become an important part of a playback! It is part of one of the key principles of design thinking: Observation and Reflection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Is everything containerized within a working Docker image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. In data science today, Docker is the industry standard for containerization of machine learning models and AI services. The Docker container is a running process that is kept isolated from the host and from other containers. One of the important consequence of this isolation is that each container interacts with its own private filesystem. A Docker image includes everything needed to run an application: code, runtime libraries, and a private filesystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Did they use a visualization to compare their model to the baseline model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. The model was compared to the baseline model by visualizing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
